{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/merrymasti015/CAP2022GRP09/blob/main/PCAMZC321_Group09_FireEventDetection_InceptionResNetV2_GG2_Gray.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_i8i1Gn6aviX"
      },
      "source": [
        "# Model Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-8cZhv4avib"
      },
      "source": [
        "#### Importing packages "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Vb0rl0hSavib"
      },
      "outputs": [],
      "source": [
        "# Import necessary modules.\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "\n",
        "from tensorflow.keras import datasets, models, layers, optimizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRDI1WPbavic",
        "outputId": "6318c13b-bc91-4ce2-cc88-ec51c8fecc48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/Fire_ImageDataSet/ModelSave\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "ModelSaveFolder = \"/content/gdrive/MyDrive/Fire_ImageDataSet/ModelSave\"\n",
        "\n",
        "\n",
        "Drive = \"/content/gdrive/MyDrive/\"\n",
        "## Define root folder\n",
        "RootFolder = Drive+\"Fire_ImageDataSet/OutputFiles\"\n",
        "\n",
        "### Where to save models\n",
        "\n",
        "ModelSaveFolder = Drive+\"Fire_ImageDataSet/ModelSave\"\n",
        "\n",
        "print(ModelSaveFolder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MvR3ivoEavic"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZKyPpcgavic"
      },
      "source": [
        "# Preparing the data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbHXiX1kavid"
      },
      "source": [
        "#### Calling test and train image directories \n",
        "\n",
        "These directories were prepared in the other notebook. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CyLnI21Aavid"
      },
      "outputs": [],
      "source": [
        "base_dir = '/content/gdrive/MyDrive/Fire_ImageDataSet/OutputFiles/GreyBaseDataSet'\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'Train')\n",
        "train_dir_fire = os.path.join(train_dir, 'Fire')\n",
        "train_dir_nofire = os.path.join(train_dir, 'Neutral')\n",
        "\n",
        "test_dir = os.path.join(base_dir, 'Test')\n",
        "test_dir_fire = os.path.join(test_dir, 'Fire')\n",
        "test_dir_nofire = os.path.join(test_dir, 'Neutral')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EvizrU_Havie",
        "outputId": "ccb41746-9ab9-4e93-8c34-322f487b89be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/MyDrive/Fire_ImageDataSet/OutputFiles/GreyBaseDataSet/Train/Neutral'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "train_dir_nofire"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXzCTnVoavie",
        "outputId": "580df435-21fc-4364-eed7-63b1984dabd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "875\n"
          ]
        }
      ],
      "source": [
        "list = os.listdir(train_dir_fire) # dir directory path\n",
        "number_files = len(list)\n",
        "print(number_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lC41tzyxavif",
        "outputId": "91e32b43-1466-4f53-8f17-47680b8f7a52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "900\n"
          ]
        }
      ],
      "source": [
        "list = os.listdir(train_dir_nofire) # dir directory path\n",
        "number_files = len(list)\n",
        "print(number_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bu-mguuaavif",
        "outputId": "fe796a97-2cc4-42cd-db2d-0269b73bcc74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "97\n"
          ]
        }
      ],
      "source": [
        "list = os.listdir(test_dir_fire) # dir directory path\n",
        "number_files = len(list)\n",
        "print(number_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7XJml3gavif",
        "outputId": "1fd52d0a-0feb-4ca6-9060-ca2356daae27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90\n"
          ]
        }
      ],
      "source": [
        "list = os.listdir(test_dir_nofire) # dir directory path\n",
        "number_files = len(list)\n",
        "print(number_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xj25MdUWavig"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKl7UyY9avig"
      },
      "source": [
        "#### Data generator & data augmentation \n",
        "\n",
        "For the large dataset it is not convenient to load all the data into memory. So we use image data generator to load the data from hard disc to memory in small batch. We do the same of the training and test set. \n",
        "\n",
        "Further, when initiating the image data generator we can do the data augmentation. This is the step to create more data from existing data by transforming the image. This artificially provides more data to train. Here we use rotation, translation, shear, zooming and horizontal flip for data augmentation. Other transformations like verticle flip is not suitable. We only do the data augmentation in the training set and not on the validation and test set. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPa0k3nAavig"
      },
      "source": [
        "### https://vijayabhaskar96.medium.com/tutorial-image-classification-with-keras-flow-from-directory-and-generators-95f75ebe5720\n",
        "\n",
        "#### https://www.pluralsight.com/guides/image-classification-using-tensorflow - Good"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUfqVkhYavig",
        "outputId": "76081931-73b3-4232-f34d-a47574305582"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1775 images belonging to 2 classes.\n",
            "Found 187 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255, \n",
        "                                  rotation_range=40,\n",
        "                                  width_shift_range=0.2,\n",
        "                                  height_shift_range=0.2,\n",
        "                                  shear_range=0.2,\n",
        "                                  zoom_range=0.2,\n",
        "                                  horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir, \n",
        "                                                   target_size=(150, 150), \n",
        "                                                   batch_size=32,\n",
        "                                                   class_mode='binary')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(test_dir, \n",
        "                                                   target_size=(150, 150), \n",
        "                                                   batch_size=32,\n",
        "                                                   class_mode='binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDOsRkKoavig",
        "outputId": "f50627b3-1f6e-49a6-acad-ab65b7700844"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1775"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "train_generator.samples "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uksipU3Havih",
        "outputId": "3c221f00-1119-49f0-f499-b31b36204857"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "187"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "test_generator.samples "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "HG-2HDdSavih"
      },
      "outputs": [],
      "source": [
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2             # pretrained CNN          \n",
        "conv_base = InceptionResNetV2(weights='imagenet', # Load weights pre-trained on ImageNet.\n",
        "                 include_top=False,               # Do not include the ImageNet classifier at the top.\n",
        "                 input_shape=(150, 150, 3))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#conv_base = (weights='imagenet',                  # Load weights pre-trained on ImageNet.\n",
        "#                include_top=False,               # Do not include the ImageNet classifier at the top.\n",
        "#                input_shape=(150, 150, 3))\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yb4cbf-zc_un",
        "outputId": "f5ab24c1-42ed-409e-8725-fad61bae7313"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inception_resnet_v2 (Functi  (None, 3, 3, 1536)       54336736  \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 13824)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               3539200   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 57,876,193\n",
            "Trainable params: 57,815,649\n",
            "Non-trainable params: 60,544\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.RMSprop(lr=2e-5),\n",
        "              metrics=['acc'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Eh6WZlldN1Y",
        "outputId": "7a407020-0943-443a-c225-6f79b482593f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xSMnmuAavih"
      },
      "source": [
        "# Training the model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B08I-b4Xavih"
      },
      "source": [
        "We pass the training data from the train_generator. We train for 30 epochs. We pass the validation data from the validation_generator.  We get validation accuracy above to 90% from this. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6wEh1ECavih",
        "outputId": "5879bfdb-a4a1-4ca9-9097-76473a53b6ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_generator, epochs=30, \n",
        "                    validation_data=test_generator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qk0dkcZ9avii"
      },
      "source": [
        "Saving the model for the future use. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWOlEi8ravii"
      },
      "outputs": [],
      "source": [
        "model_name = 'InceptionResNetV2_Gray.h5'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgLNARCQavii"
      },
      "outputs": [],
      "source": [
        "# Saving Model\n",
        "model_name = 'InceptionResNetV2_Gray.h5'\n",
        "model.save(ModelSaveFolder+'/'+model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4f9xLLyjavii"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RG-1dEh3avii"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "model = keras.models.load_model(ModelSaveFolder+'/'+model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_aklWJmavii"
      },
      "source": [
        "#### Visualization of the learning \n",
        "\n",
        "Training gives four sets of values in each eopch\n",
        "\n",
        "- Training accuracy \n",
        "- Validation accuracy \n",
        "- Training loss \n",
        "- Validation loss "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9AJqdGwavii"
      },
      "outputs": [],
      "source": [
        "# Dictionary to extract the numbers \n",
        "hist_dict = history.history\n",
        "\n",
        "# Training and validation accuracy \n",
        "training_acc = hist_dict['acc']\n",
        "validation_acc = hist_dict['val_acc']\n",
        "\n",
        "# Training and validation loss \n",
        "training_loss = hist_dict['loss']\n",
        "validation_loss = hist_dict['val_loss']\n",
        "\n",
        "# Number of epochs \n",
        "epoches = range(1, 1 + len(training_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38iDJb5Ravii"
      },
      "source": [
        "#### Function to make plot "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXAS2i9Vavii"
      },
      "outputs": [],
      "source": [
        "def plot_func(entity):\n",
        "    \n",
        "    '''\n",
        "    This function produces plot to compare the performance \n",
        "    between train set and validation set. \n",
        "    entity can be loss of accuracy. \n",
        "    '''\n",
        "    \n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(epoches, eval('training_' + entity), 'r')\n",
        "    plt.plot(epoches, eval('validation_' + entity), 'b')\n",
        "    plt.legend(['Training ' + entity, 'Validation ' + entity])\n",
        "    plt.xlabel('Epoches')\n",
        "    plt.ylabel(entity)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtoEPNqLavij"
      },
      "outputs": [],
      "source": [
        "plot_func('loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjC1Zr8tavij"
      },
      "outputs": [],
      "source": [
        "plot_func('acc')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bv2QzaUoavij"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fN5p6Oe2avij"
      },
      "source": [
        "#### Getting the labels and predictions "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xV_X_r2qavij"
      },
      "outputs": [],
      "source": [
        "len(test_generator)\n",
        "\n",
        "#test_generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDG-_Ik3avij"
      },
      "outputs": [],
      "source": [
        "# taking first batch from the generator \n",
        "img, label = test_generator[5] \n",
        "print(label)\n",
        "print(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IioJm4lwavij"
      },
      "outputs": [],
      "source": [
        "# taking first batch from the generator \n",
        "img, label = test_generator[0] \n",
        "\n",
        "# Predicting the images from the first batch \n",
        "pred = np.round(model.predict(img)).flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCrqrhjGavij"
      },
      "outputs": [],
      "source": [
        "len(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnAocZAjavij"
      },
      "outputs": [],
      "source": [
        "pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1QRCZWoavik"
      },
      "outputs": [],
      "source": [
        "# Numeric to semantic labels \n",
        "label_dict = {1.0: 'No fire', 0.0: 'Fire'}\n",
        "\n",
        "# Generating collage of plots \n",
        "fig = plt.figure(figsize=(10, 9))\n",
        "plt.title('Classification by the model')\n",
        "plt.axis('off')\n",
        "\n",
        "for i, img_i in enumerate(img[:20]):\n",
        "    ax = fig.add_subplot(4, 5, i+1)\n",
        "    plt.axis('off')\n",
        "    plt.title(label_dict[pred[i]], y=-0.2)\n",
        "    ax.imshow(img_i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOxuFIBQavik"
      },
      "source": [
        "#### Extracting misclassified images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVkMcV7Mavik"
      },
      "outputs": [],
      "source": [
        "print(range(len(test_generator)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCBQCTZ1avik"
      },
      "outputs": [],
      "source": [
        "# Lists for missed fire images and missed non-fire images\n",
        "msd_fire = []\n",
        "msd_nofire = []\n",
        "\n",
        "# Iterating through all the batches \n",
        "#for j in range(31):\n",
        "for j in range(len(test_generator)):\n",
        "    print(j)\n",
        "    img, label = test_generator[j] \n",
        "    pred = np.round(model.predict(img)).flatten()\n",
        "    bool_list = label == pred\n",
        "\n",
        "    # bool_list is False when there is misclassification \n",
        "    for i, e in enumerate(bool_list):\n",
        "        if e == False:\n",
        "            \n",
        "            # separating labels (fire and non-fire)\n",
        "            if label[i] == 0:\n",
        "                msd_fire.append(img[i])\n",
        "            else:\n",
        "                msd_nofire.append(img[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9CZnI76avik"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypNdc2Tjavik"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmHZ-BBZavik"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6sY4upDavik"
      },
      "source": [
        "#### Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSr6rWetavik"
      },
      "outputs": [],
      "source": [
        "# total number of sample in test set in each class \n",
        "n_class = 187\n",
        "\n",
        "# number of misclassified fire and non-fire images \n",
        "nm_fire, nm_nofire = len(msd_fire), len(msd_nofire)\n",
        "\n",
        "# confusion matrix (flattened)\n",
        "conf_mat = [n_class-nm_fire, nm_fire, nm_nofire, n_class-nm_nofire]\n",
        "\n",
        "# visualization of confusion matrix \n",
        "fig = plt.figure(figsize=(4, 4))\n",
        "for i, j in enumerate(conf_mat):\n",
        "    ax = fig.add_subplot(2, 2, i+1)\n",
        "    ax.imshow([[j]], vmin=0, vmax=1000, cmap='copper_r')\n",
        "    ax.text(-0.2, 0.1, j, c='r', fontsize=30)\n",
        "    ax.axis('off')\n",
        "\n",
        "# bringing blocks tighter \n",
        "fig.tight_layout()\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSokTTU0avik"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# total number of sample in test set in each class \n",
        "n_classFire    = 97\n",
        "n_classNeutral = 90\n",
        "\n",
        "# number of misclassified fire and non-fire images \n",
        "nm_fire, nm_nofire = len(msd_fire), len(msd_nofire)\n",
        "\n",
        "# confusion matrix (flattened)\n",
        "conf_mat = [n_classFire-nm_fire, nm_fire, nm_nofire, n_classNeutral-nm_nofire]\n",
        "\n",
        "# confusion matrix (flattened)\n",
        "#conf_mat = [n_class-nm_fire, nm_fire, nm_nofire, n_class-nm_nofire]\n",
        "\n",
        "# visualization of confusion matrix \n",
        "fig = plt.figure(figsize=(4, 4))\n",
        "for i, j in enumerate(conf_mat):\n",
        "    ax = fig.add_subplot(2, 2, i+1)\n",
        "    ax.imshow([[j]], vmin=0, vmax=1000, cmap='copper_r')\n",
        "    ax.text(-0.2, 0.1, j, c='r', fontsize=30)\n",
        "    ax.axis('off')\n",
        "\n",
        "# bringing blocks tighter \n",
        "fig.tight_layout()\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2LUrEeKavik"
      },
      "source": [
        "#### Showing mis-classified fire images "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1mZQdVGavil"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10, 7))\n",
        "plt.title('Fire images classified as non-fire')\n",
        "plt.axis('off')\n",
        "for i, img_i in enumerate(msd_fire):        \n",
        "    ax = fig.add_subplot(4, 5, i+1)\n",
        "    ax.imshow(img_i)\n",
        "    ax.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTU53s6Uavil"
      },
      "source": [
        "Some of the misclassified figure have fire but that is too small. So even human observer is easy to confuse with them. Though some of the big explicit fire images are misclassified too. May be that is painting of fire but not the picture. Misclassified fire images are mostly bonfire, stove fire, fire tourch, kitchen fire etc. This is not big surprise because there were not enough fire sample in training set in that categories.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxttrQBKavil"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIJ-L3C_avil"
      },
      "source": [
        "#### Showing mis-classified non-fire images. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cCgQmaUavil"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10, 4))\n",
        "plt.title('Non-fire images classified as fire')\n",
        "plt.axis('off')\n",
        "for i, img_i in enumerate(msd_nofire):        \n",
        "    ax = fig.add_subplot(2, 5, i+1)\n",
        "    ax.imshow(img_i)\n",
        "    ax.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNnbHphkavil"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEjxceeTavil"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqTaEY2Javil"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUMj_JsWavil"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65yRKrkQavil"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AACkYSWavil"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fu5dSKzcavil"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzO4XMI9avil"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fJ2XfY0avil"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_XOOwhxavil"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwXJu0xgavil"
      },
      "source": [
        "# Fine tuning the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvXzbmuEavim"
      },
      "source": [
        "#### Unlocking the top convolutional block \n",
        "\n",
        "We trained previosuly with only top layer removed from VGG16. Here we unlock top base layer from VGG16 and fine tune the model. Doing so we reduce the learning rate from $10^{-4}$ to $10^{-5}$. We train for the 10 epoches. The model surpass the validation accuracy of 97% shortly after 30 epochs. It is not unlikely to improve the model after 50 epochs. But I am happy with this for now. The future plan is to check with other pre-trained model rather. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wlparbh8avim"
      },
      "outputs": [],
      "source": [
        "conv_base.trainable = True\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "    if layer.name == 'block5_conv1':\n",
        "        set_trainable = True\n",
        "    else:\n",
        "        set_trainable = False\n",
        "    \n",
        "model.compile(loss='binary_crossentropy', \n",
        "             optimizer=optimizers.RMSprop(lr=1e-5), \n",
        "             metrics=['acc'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRHjRt6yavim"
      },
      "source": [
        "#### Fitting the model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3P_sdEabavim"
      },
      "outputs": [],
      "source": [
        "history = model.fit_generator(train_generator, epochs=10, \n",
        "                             validation_data=test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wglX40_navin"
      },
      "outputs": [],
      "source": [
        "model_name = 'InceptionResNetV2_Prediction_fine_tuned_gray.h5'\n",
        "\n",
        "model.save(ModelSaveFolder+'/'+model_name)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pj-qCqs1avin"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRjdXuY9avin"
      },
      "source": [
        "#### Visualization of fine tuning process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyolbcreavin"
      },
      "outputs": [],
      "source": [
        "hist_dict = history.history\n",
        "\n",
        "training_accuracy = hist_dict['acc']\n",
        "validation_accuracy = hist_dict['val_acc']\n",
        "\n",
        "training_loss = hist_dict['loss']\n",
        "validation_loss = hist_dict['val_loss']\n",
        "\n",
        "epoches = range(1, 1 + len(training_accuracy))\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3nQymx1avin"
      },
      "outputs": [],
      "source": [
        "plot_func('loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poJsQH3cavin"
      },
      "outputs": [],
      "source": [
        "plot_func('accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYaj7stGavio"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4LgWST8avio"
      },
      "source": [
        "# Error Analysis\n",
        "\n",
        "In this section we analyze the error of the model, i.e. mis-classified images. We first see few examples of the correctly classified images. Then we visualize the confusion matrix. And finally, we see separately fire images classified as non-fire and non-fire images classified as fire.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AXN5bDLavio"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DX4osp5Oavio"
      },
      "outputs": [],
      "source": [
        "model_name = 'InceptionResNetV2_Prediction_fine_tuned_gray.h5'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JikrJ-MGavio"
      },
      "outputs": [],
      "source": [
        "# Loading the saved model \n",
        "model = keras.models.load_model(ModelSaveFolder+'/'+model_name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYJiq0Uwavio"
      },
      "source": [
        "#### Getting the labels and predictions "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KWADZT2avio"
      },
      "outputs": [],
      "source": [
        "len(test_generator)\n",
        "\n",
        "#test_generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kfMUGe2avio"
      },
      "outputs": [],
      "source": [
        "# taking first batch from the generator \n",
        "img, label = test_generator[5] \n",
        "print(label)\n",
        "print(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1CJfBJ2avio"
      },
      "outputs": [],
      "source": [
        "# taking first batch from the generator \n",
        "img, label = test_generator[0] \n",
        "\n",
        "# Predicting the images from the first batch \n",
        "pred = np.round(model.predict(img)).flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LexIyXlNavip"
      },
      "outputs": [],
      "source": [
        "len(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMHLhuwMavip"
      },
      "outputs": [],
      "source": [
        "pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MHrlSaMavip"
      },
      "outputs": [],
      "source": [
        "# Numeric to semantic labels \n",
        "label_dict = {1.0: 'No fire', 0.0: 'Fire'}\n",
        "\n",
        "# Generating collage of plots \n",
        "fig = plt.figure(figsize=(10, 9))\n",
        "plt.title('Classification by the model')\n",
        "plt.axis('off')\n",
        "\n",
        "for i, img_i in enumerate(img[:20]):\n",
        "    ax = fig.add_subplot(4, 5, i+1)\n",
        "    plt.axis('off')\n",
        "    plt.title(label_dict[pred[i]], y=-0.2)\n",
        "    ax.imshow(img_i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2I4EKPVWavip"
      },
      "source": [
        "#### Extracting misclassified images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EITghBF3avip"
      },
      "outputs": [],
      "source": [
        "print(range(len(test_generator)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvk2w4M4avip"
      },
      "outputs": [],
      "source": [
        "# Lists for missed fire images and missed non-fire images\n",
        "msd_fire = []\n",
        "msd_nofire = []\n",
        "\n",
        "# Iterating through all the batches \n",
        "#for j in range(31):\n",
        "for j in range(len(test_generator)):\n",
        "    print(j)\n",
        "    img, label = test_generator[j] \n",
        "    pred = np.round(model.predict(img)).flatten()\n",
        "    bool_list = label == pred\n",
        "\n",
        "    # bool_list is False when there is misclassification \n",
        "    for i, e in enumerate(bool_list):\n",
        "        if e == False:\n",
        "            \n",
        "            # separating labels (fire and non-fire)\n",
        "            if label[i] == 0:\n",
        "                msd_fire.append(img[i])\n",
        "            else:\n",
        "                msd_nofire.append(img[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCxUjCCvavip"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3LMd6U1avip"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9s2LCKTavip"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8l80YVtnavip"
      },
      "source": [
        "#### Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RsXcmZigaviq"
      },
      "outputs": [],
      "source": [
        "# total number of sample in test set in each class \n",
        "n_class = 195\n",
        "\n",
        "# number of misclassified fire and non-fire images \n",
        "nm_fire, nm_nofire = len(msd_fire), len(msd_nofire)\n",
        "\n",
        "# confusion matrix (flattened)\n",
        "conf_mat = [n_class-nm_fire, nm_fire, nm_nofire, n_class-nm_nofire]\n",
        "\n",
        "# visualization of confusion matrix \n",
        "fig = plt.figure(figsize=(4, 4))\n",
        "for i, j in enumerate(conf_mat):\n",
        "    ax = fig.add_subplot(2, 2, i+1)\n",
        "    ax.imshow([[j]], vmin=0, vmax=1000, cmap='copper_r')\n",
        "    ax.text(-0.2, 0.1, j, c='r', fontsize=30)\n",
        "    ax.axis('off')\n",
        "\n",
        "# bringing blocks tighter \n",
        "fig.tight_layout()\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Y9s7Wx-aviq"
      },
      "outputs": [],
      "source": [
        "# total number of sample in test set in each class \n",
        "#n_class = 195\n",
        "\n",
        "# number of misclassified fire and non-fire images \n",
        "#nm_fire, nm_nofire = len(msd_fire), len(msd_nofire)\n",
        "\n",
        "# total number of sample in test set in each class \n",
        "n_classFire    = 97\n",
        "n_classNeutral = 90\n",
        "\n",
        "# number of misclassified fire and non-fire images \n",
        "nm_fire, nm_nofire = len(msd_fire), len(msd_nofire)\n",
        "\n",
        "# confusion matrix (flattened)\n",
        "conf_mat = [n_classFire-nm_fire, nm_fire, nm_nofire, n_classNeutral-nm_nofire]\n",
        "\n",
        "# confusion matrix (flattened)\n",
        "#conf_mat = [n_class-nm_fire, nm_fire, nm_nofire, n_class-nm_nofire]\n",
        "\n",
        "# visualization of confusion matrix \n",
        "fig = plt.figure(figsize=(4, 4))\n",
        "for i, j in enumerate(conf_mat):\n",
        "    ax = fig.add_subplot(2, 2, i+1)\n",
        "    ax.imshow([[j]], vmin=0, vmax=1000, cmap='copper_r')\n",
        "    ax.text(-0.2, 0.1, j, c='r', fontsize=30)\n",
        "    ax.axis('off')\n",
        "\n",
        "# bringing blocks tighter \n",
        "fig.tight_layout()\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6jxMNmhaviq"
      },
      "source": [
        "#### Showing mis-classified fire images "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCgVHQ8laviq"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10, 7))\n",
        "plt.title('Fire images classified as non-fire')\n",
        "plt.axis('off')\n",
        "for i, img_i in enumerate(msd_fire):        \n",
        "    ax = fig.add_subplot(4, 5, i+1)\n",
        "    ax.imshow(img_i)\n",
        "    ax.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MofQ5A5raviq"
      },
      "source": [
        "Some of the misclassified figure have fire but that is too small. So even human observer is easy to confuse with them. Though some of the big explicit fire images are misclassified too. May be that is painting of fire but not the picture. Misclassified fire images are mostly bonfire, stove fire, fire tourch, kitchen fire etc. This is not big surprise because there were not enough fire sample in training set in that categories.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ST87aoGcaviq"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAZ-f6Y4aviq"
      },
      "source": [
        "#### Showing mis-classified non-fire images. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hz1Uj2A2aviq"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10, 4))\n",
        "plt.title('Non-fire images classified as fire')\n",
        "plt.axis('off')\n",
        "for i, img_i in enumerate(msd_nofire):        \n",
        "    ax = fig.add_subplot(2, 5, i+1)\n",
        "    ax.imshow(img_i)\n",
        "    ax.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plwmO8zGaviq"
      },
      "source": [
        "Looking at this mis-classified set some of the picture actually seem to have fire. So, the problem is about the mis-labeling. Others don't have fire but have artificial red light or are picture with hue of dawn and dusk almost appearing as fire. \n",
        "\n",
        "Overall the model has done very good job separating those images with solid 97% accuracy in out of sample images. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yvoyd3joavir"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8JonPckavir"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7M7Ra-Lavir"
      },
      "source": [
        "## Apply new set "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9URdrtp1avir"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import array_to_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tAZEcetavir"
      },
      "outputs": [],
      "source": [
        "# New set are kept C:/1-GG/CAP5/FireDetection/ApplySet/ApplyImageSet\n",
        "Drive = \"/content/gdrive/MyDrive/\"\n",
        "## Define root folder\n",
        "RootFolder = Drive+\"Fire_ImageDataSet/OutputFiles\"\n",
        "newImagePath = Drive + 'Fire_ImageDataSet/ApplySet'\n",
        "\n",
        "ModelSaveFolder = \"/content/gdrive/MyDrive/Fire_ImageDataSet/ModelSave\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-HeBa7Uavir"
      },
      "outputs": [],
      "source": [
        "model_name = 'InceptionResNetV2_Prediction_fine_tuned_gray.h5'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbyhJDJ9avir"
      },
      "outputs": [],
      "source": [
        "model_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDAliqY2avir"
      },
      "outputs": [],
      "source": [
        "# Loading the saved model \n",
        "model = keras.models.load_model(ModelSaveFolder+'/'+model_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X00jbnvZavis"
      },
      "outputs": [],
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drAagnnpavis"
      },
      "outputs": [],
      "source": [
        "test_generatorapply = test_datagen.flow_from_directory(newImagePath, \n",
        "                                                   target_size=(150, 150), \n",
        "                                                   batch_size=32,\n",
        "                                                   class_mode='binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "_sps0m7_avis"
      },
      "outputs": [],
      "source": [
        "len(test_generatorapply)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3KRWmNfavis"
      },
      "outputs": [],
      "source": [
        "test_generatorapply[len(test_generatorapply)-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Z7Cjx8Davis"
      },
      "outputs": [],
      "source": [
        "print(len(test_generatorapply))\n",
        "\n",
        "#test_generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72Qxoz0Cavis"
      },
      "outputs": [],
      "source": [
        "# taking first batch from the generator \n",
        "#img, label = test_generatorapply[0] \n",
        "img, label = test_generatorapply[len(test_generatorapply)-1] \n",
        "print(label)\n",
        "print(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZUhe2Oeavis"
      },
      "outputs": [],
      "source": [
        "# taking first batch from the generator \n",
        "img, label = test_generatorapply[0] \n",
        "\n",
        "# Predicting the images from the first batch \n",
        "pred = np.round(model.predict(img)).flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HySgWEHiavis"
      },
      "outputs": [],
      "source": [
        "len(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1Z5Hbhlavis"
      },
      "outputs": [],
      "source": [
        "pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmMhRDUYavis"
      },
      "outputs": [],
      "source": [
        "pred[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0AMQViQavit"
      },
      "outputs": [],
      "source": [
        "# Numeric to semantic labels \n",
        "label_dict = {1.0: 'No fire', 0.0: 'Fire'}\n",
        "\n",
        "# Generating collage of plots \n",
        "fig = plt.figure(figsize=(10, 9))\n",
        "plt.title('Classification by the model')\n",
        "plt.axis('off')\n",
        "\n",
        "for i, img_i in enumerate(img[:20]):\n",
        "    ax = fig.add_subplot(4, 5, i+1)\n",
        "    plt.axis('off')\n",
        "    plt.title(label_dict[pred[i]], y=-0.2)\n",
        "    ax.imshow(img_i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7DcH4qFavit"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taZRCRKZavit"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98PWPQjLavit"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkCC9uatavit"
      },
      "source": [
        "##  E N D "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "PCAMZC321_Group09_FireEventDetection_InceptionResNetV2-GG2-Gray.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "38iDJb5Ravii",
        "fN5p6Oe2avij",
        "dOxuFIBQavik",
        "T6sY4upDavik",
        "I2LUrEeKavik",
        "SIJ-L3C_avil",
        "nvXzbmuEavim",
        "iRHjRt6yavim",
        "qRjdXuY9avin"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}